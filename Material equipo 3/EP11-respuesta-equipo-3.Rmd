---
title: 'EP11: herramientas avanzadas para modelos de regresión'
author: "Equipo 3"
date: "2025-06-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Actividades

> Para este ejercicio usaremos los datos de medidas anatómicas recolectados por Heinz et al. (2003) que ya hemos utilizado en los ejercicios prácticos anteriores (disponibles en el archivo "EP09 Datos.csv"), con la adición de las variables IMC y EN consideradas en el ejercicio práctico anterior.s

## Semilla y Librerías

> Definir la semilla a utilizar, que corresponde a los primeros cinco dígitos del RUN del integrante de mayor edad del equipo.

```{r}
library(car)
library(caret)
library(dplyr)
library(ggpubr)
library(leaps)
library(pROC)
library(psych)

set.seed(20994)
```

## Lectura y creación de datos

> Seleccionar una muestra de 100 personas, asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso”.

```{r}
set.seed(20994)
# Leer los datos (con separador ; y coma decimal)
datos <- read.csv2("EP09 Datos.csv")

# Convertir columnas numéricas de coma a punto decimal
datos <- datos %>%
  mutate(across(where(is.character), ~ as.numeric(gsub(",", ".", .))))

# Calcular IMC
datos <- datos %>%
  mutate(IMC = Weight / ((Height / 100)^2),
         EN = ifelse(IMC >= 23.2, 1, 0))  # 1 = sobrepeso, 0 = no sobrepeso


# Establecer semilla de aleatorización
set.seed(20994)
sobrepeso <- datos %>% filter(EN == 1) %>% sample_n(50)

set.seed(20994)
no_sobrepeso <- datos %>% filter(EN == 0) %>% sample_n(50)


# Combinar la muestra balanceada
muestra <- bind_rows(sobrepeso, no_sobrepeso) %>%
  slice_sample(prop = 1, replace = FALSE)  # mezclar
```

## Regresión Lineal Múltiple con `leaps`

> Usando las herramientas del paquete leaps, realizar una búsqueda exhaustiva para seleccionar entre dos y ocho predictores que ayuden a estimar la variable Peso (Weight), obviamente sin considerar las nuevas variables IMC ni EN, y luego utilizar las funciones del paquete caret para construir un modelo de regresión lineal múltiple con los predictores escogidos y evaluarlo usando bootstrapping.

```{r, warning = FALSE}
comb <- regsubsets(Weight ~ ., data = muestra, nbest = 1, nvmax = 8, method = "exhaustive", force.out = c("IMC", "EN"))
plot(comb)
resumen <- summary(comb)

pos_bic_min <- which.min(resumen$bic)
comb_mejor_bic <- resumen$which[pos_bic_min, ]
var_mejor_bic <- names(comb_mejor_bic)[comb_mejor_bic]
nombre_mejor_bic <- unique(gsub("(.*)\\d$", "\\1", var_mejor_bic))
cat("Nombre del mejor modelo según BIC:\n")
print(nombre_mejor_bic)

# confección del modelo
mejores_predictores = nombre_mejor_bic[-1]
formula_mejor = as.formula(paste("Weight ~", paste(mejores_predictores, collapse = " + ")))
set.seed(20994)
modelo_tr = train(formula_mejor, data = muestra, method = "lm", trControl = trainControl(method = "boot", number = 100))
modelo_leaps = modelo_tr$finalModel
```

### Confiabilidad de RLM `leaps`

#### 1. La variable de respuesta `Weight` es cuantitativa y continua.
#### 2. Los predictores a utilizar: `Chest.diameter`, `Waist.Girth`, `Hip.Girth`, `Thigh.Girth`, `Forearm.Girth` y `Height`, son variables cuantitativas y continuas.
#### 3. Los predictores previamente mencionados presentan variabilidad.


#### 4. Relación lineal entre predictores y respuesta 
```{r}
set.seed(20994)

rlm_leaps_nuevo <- lm(formula_mejor, muestra)

cat("Prueba de curvatura para predictores")
residualPlots(rlm_leaps_nuevo)
marginalModelPlots(rlm_leaps_nuevo)
```

Cómo bien se puede observar, el gráfico de fitted values ilustra la linealidad de las variables predictoras respecto a la variable de salida.

#### 5. Distribución de residuos debe ser cercana a la normal

```{r}
normalidad_residuos <- shapiro.test(residuals(rlm_leaps_nuevo))
p_valor_normalidad <- normalidad_residuos$p.value
```

Al obtener un p-value de $0.092674$, no tenemos evidencia suficiente para rechazar la normalidad de los residuos, por lo que con un $95\%$ de confianza los datos sostienen que los residuos siguen una distribución normal centrada en 0.

#### 6. La variabilidad de los residuos debe ser aproximadamente constante 

```{r}
variabilidad_residuos <- ncvTest(rlm_leaps_nuevo)
print(variabilidad_residuos)
p_valor_variabilidad <- variabilidad_residuos$p.value
```

Al obtener un p-value de $`r p_valor_variabilidad`$, no tenemos evidencia suficiente para rechazar el comportamiento aproximado constante de los residuos, por lo que con un $95\%$ de confianza los datos sostienen que la variablidad de los residuos es constante de manera aproximada.

#### 7. Residuos independientes

```{r}
set.seed(20994)
durbinWatsonTest(rlm_leaps_nuevo)
```
En base a la prueba de Durbin-Watson para correlación entre variables, cómo se observa un p-value de $0.456$, fallamos en rechazar la hipótesis nula, por lo tanto se concluye que no tenemos evidencia suficiente para descartar que las observaciones no presenten autocorrelación.

#### 8. Multicolinealidad
```{r}
set.seed(20994)

cat("Factores de inflación de la varianza:\n")
print(vif(modelo_leaps))
cat("Valores de tolerancia:\n")
print(1 / vif(modelo_leaps))
```

Observando detenidamente los factores de inflación de la varianza, los más problemáticos vendrían a ser, en su respectivo órden:
- `Hip.Girth`
- `Waist.Girth`
- `Thigh Girth`
- `Forearm.Girth`

Estos se consideran problematicos ya que el $VIF$ oscila entre 5 y 10 ($5 \leq VIF \leq 10$). Más aún, notar que los valores de tolerancia asociadas a las variables muestran señales de colinealidad entre sí, notando que `Height` y `Chest.diameter` son las únicas variables cuyos valores de tolerancia son mayores que $0.2$. 
De esto, sabemos que la mayoría de variables asociadas al modelo poseen multicolinealidad preocupante, por lo que los resultados pueden verse significativamente afectados,

#### 9. Las estimaciones de los coeficientes del modelo no debe estar alterados por unos pocas observaciones influyentes.
```{r}
set.seed(20994)
apalancamiento <- (length(mejores_predictores)+1)/length(muestra)
influencePlot(rlm_leaps_nuevo)
```

Analizando cuidadosamente las 5 observaciones entregadas (8, 42, 78, 86 y 96), considerando un valor de apalancamiento de $`r apalancamiento`$, notamos que:
- La observación 78 tiene un alto valor de `StudRes`, en el gráfico es notorio que es un valor "outlier", además tiene la distancia de Cook más elevada de entre todos los otros predictores.
- La observación 42 tiene un alto valor de `StudRes`, si bien su distancia de Cook no es muy elevada a comparación de la observación anteriormente vista, igualmente debe de tenerse precaución con esta.


```{r}
set.seed(20994)
mmps(rlm_leaps_nuevo, terms = ~ 1, 
        col = "steelblue", pch = 20, col.line = c("steelblue", "red"),
        smooth = list(smoother = loessLine, span = 1),
        id = list(n = 6, cex = 0.7, location = "lr"),
        main = "Relación marginal con predicciones (RLM 1)", sub = " ")
```

#### Conclusión confiabilidad:
Si bien se cumplieron las 9 condiciones, se puede mejorar sustancialmente lo que vendría a ser el VIF, se mencionó que si bien existen relaciones relativamente fuertes entre dos o más predictores, no es realmente una imposición obligatoria para la confiabilidad del RLM, pero se debe de mencionar por la posible inestabilidad que está asociada al modelo.

### Poder predictivo del modelo
```{r}
summary(modelo_leaps)
cat("Poder Predictivo del Modelo (evaluado con Bootstrapping): \n")
print(modelo_tr)
```
Del entrenamiento obtenido por medio de bootstraping, se obtuvieron las siguientes métricas:

- $RMSE = 2.229488$, esto implica que, en promedio, tiene un error medio de $2,2 [kg]$
- $R^2 = 0.9730712$, indica que puede explicar un $97,31\%$ de la variabilidad del peso de una persona.


---



## Regresión Lineal Múltiple con `caret`
> Haciendo un poco de investigación sobre el paquete caret, en particular cómo hacer Recursive Feature Elimination (RFE), construir un modelo de regresión lineal múltiple para predecir la variable IMC que incluya entre 10 y 20 predictores, seleccionando el conjunto de variables que maximice R2 y que use cinco repeticiones de validación cruzada de cinco pliegues para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura ni estado nutricional –Weight, Height, EN respectivamente). 

Para el paquete `caret`, existen dos implementaciones de RFE.

**La primera implementación tiene la siguiente secuencia de pasos:**

```{eval=FALSE}
ALGORITMO 1
1.  entrenar el modelo utilizando todos los predictores
2.  calcular el rendimiento del modelo
3.  calcular la importancia de cada variable
4.  para cada subconjunto de tamaño S_i, i = 1...S:
5.      mantener el S_i cuyas variables tengan mayor importancia
6.      entrenar el modelo con los predictores en S_i
7.      calcular el rendimiento del modelo
8.  fin
9.  calcular el perfil de rendimiento por sobre S_i
10. determinar la cantidad apropiada de predictores
11. usar el modelo correspondiente al S_i óptimo
```

El algoritmo tiene un enfoque iterativo por sobre los $S_i$ mejores predictores candidatos, luego se va evaluando con cada entrenamiento del modelo con las nuevas mejores predictores el rendimiento del nuevo modelo hasta agotar todas las $i: 1, \dots , S$ posibles variables. La implementación en cuestión se invoca con `rfeIter``.

Ahora, la segunda implementación proviene de un algoritmo con un enfoque de remuestreo, cómo fué previamente visto el remuestreo (cómo lo puede ser bootstrap o validación cruzada) permite tomar en cuenta la variabilidad del modelo, por lo que algoritmo 2 sigue la siguiente secuencia de pasos:

```{eval=FALSE}
ALGORITMO 2
1.   para cada itereación de remuestreo:
2.      particionar los datos en conjunto de entrenamiento y prueba
3.      entrenar el modelo utilizando todos los predictores
4.      predecir las muestras del conjunto de prueba
5.      calcular la importancia de cada variable
6.      para cada subconjunto de tamaño S_i, i = 1...S:
7.          mantener el S_i cuyas variables tengan mayor importancia
8.          entrenar el modelo con los predictores en S_i
9.          predecir con la muestra de prueba
10.     fin
11.  fin
12.  calcular el perfil de rendimiento por sobre S_i usando el conjunto de prueba
13.  determinar la cantidad apropiada de predictores
14.  estimar la lista final de de predictores a mantener en el modelo final
14.  ajustar el modelo basandose en S_i optimo usando el conjunto de entrenamiento original.
```

Esencialmente, es el algoritmo 1 con una "máscara" de remuestreo. Esta implementación se puede invocar por medio de `rfe()`, donde:

- `x`: Es el dataframe de predictores para entrenamiento.
- `y`: Es un vector que corresponde a la salida del conjunto de entrenamiento.
- `sizes`:
- `rfeControl`:

```{r}
# modelo rlm
set.seed(20994)  
datos <- rbind(sobrepeso, no_sobrepeso)
datos<- datos[sample(1:nrow(datos)), ]
#combinaciones <- regsubsets(IMC ~ ., data = datos, nbest=1, nvmax = 20, method = "exhaustive", #force.out=c("Weight", "Height", "EN"))

#resumen_combinaciones <- summary(combinaciones)
#i_r2a_maximo <- which.max(resumen_combinaciones[["adjr2"]])
#mejor_comb_r2a <- resumen_combinaciones[["which"]][i_r2a_maximo, ]
#comb_mejor_r2a <- names(mejor_comb_r2a[mejor_comb_r2a == TRUE])
#nombres_mejor_r2a <- unique(gsub("7(.*)\\d$", "\\1i", comb_mejor_r2a))
#pred_mejor_r2a <- paste(nombres_mejor_r2a[-1], collapse = " + ")
#fmla_mejor_r2a <- as.formula(paste("IMC", pred_mejor_r2a, sep = " ~ "))
#modelo_mejor_r2a <- rfe(form = fmla_mejor_r2a, data = datos)

rfe_control <- rfeControl(functions = lmFuncs, 
                          method = "repeatedcv", 
                          number = 5, 
                          repeats = 5, 
                          verbose = FALSE)

modelo_rfe <- rfe(form = IMC ~ . - Height - Weight - EN, data = datos, sizes = 10:20, metric = "Rsquared", maximize = TRUE, rfeControl = rfe_control)

Graficorfe <- ggplot(modelo_rfe) + theme_pubr()
Graficorfe <- ggpar(Graficorfe, title = "Búsqueda RFE (RLM 2)")
print(Graficorfe)
RLM_caret<-modelo_rfe$fit
print(modelo_rfe)
predictores<-predictors(modelo_rfe)
print(predictores)

predictores_concat <- paste(predictores, collapse = " + ")
formula_str <- paste("IMC ~", predictores_concat)
formularfl <- as.formula(formula_str)

```

Del grafico anterior se puede concluir que el modelo que maximiza el $R^{2}$, este utiliza 12 predictores

- Gender            

- Knees.diameter

- Thigh.Girth

- Biiliac.diameter

- Elbows.diameter

- Forearm.Girth

- Waist.Girth

- Chest.diameter

- Wrists.diameter

- Ankle.Minimum.Girth

- Biacromial.diameter 

- Wrist.Minimum.Girth

Dando como resultado el siguiente modelo:
```{r}
set.seed(20994)
RLMf<-lm( formularfl , data = datos)
summary(RLMf)


```
Para continuar, se  verificara la confiabilidad del modelo.


### Confiabilidad del RLM optimizando $R^{2}$

#### 1) La variable de respuesta `IMC` es cuantitativa y continua.

Se cumple, ya que el IMC es una variable cuantitativa y continua.

#### 2) Los predictores son variables cuantitativas o dicotomicas

Se cumple debido a que la mayoria son medidas en centimetros y la variable gender es dicotomica

#### 3) Los predictores presentan grado de variabilidad

```{r}
cat("Variabilidad Gender: ",var(datos$Gender),"\n")
cat("Variabilidad Knees.diameter: ",var(datos$Knees.diameter),"\n")
cat("Variabilidad Thigh.Girth: ",var(datos$Thigh.Girth),"\n")
cat("Variabilidad Biiliac.diameter: ",var(datos$Biiliac.diameter),"\n")
cat("Variabilidad Elbows.diameter: ",var(datos$Elbows.diameter),"\n")
cat("Variabilidad Forearm.Girth: ",var(datos$Forearm.Girth),"\n")
cat("Variabilidad Waist.Girth: ",var(datos$Waist.Girth),"\n")
cat("Variabilidad Chest.diameter: ",var(datos$Chest.diameter),"\n")
cat("Variabilidad Wrists.diameter: ",var(datos$Wrists.diameter),"\n")
cat("Variabilidad Ankle.Minimum.Girth: ",var(datos$Ankle.Minimum.Girth),"\n")
cat("Variabilidad Biacromial.diameter: ",var(datos$Biacromial.diameter),"\n")
cat("Variabilidad Wrist.Minimum.Girth: ",var(datos$Wrist.Minimum.Girth),"\n")


```
Como se puede ver, ninguna varianza es igual a 0, por lo tanto esta condicion se cumple

Ahora se generaran los graficos para las condiciones 4 a 6
```{r, message=FALSE, warning=FALSE}
set.seed(20994)
residualPlots(RLMf)
cat("\n")
marginalModelPlots(RLMf)
ncvTest(RLMf)
```



#### 4) Los predictores estan relacionados linealmente con la respuesta.
De los graficos anteriores se puede ver que la mayoria de los graficos los residuos no siguen algun patron reconocible y se encuentran dispersos de buena manera, en el test de Tukey se obtiene que $p-value= 0.11448 >0.05$, concluyendo que no existe evidencia suficiente para rechazar la condicion analizada

#### 5) Distribucion normal de residuos
```{r}
set.seed(20994)
residuos<-resid(RLMf)
#media muy cercana a 0
print(mean(residuos))

#test de normalidad
#P-value mayor a 0.05m permitiendo concluir que no existe evidencia suficiente para rechazar que lo residuos no tengan una disribucion normal
print(shapiro.test(residuos))
```
Primero que nada, la media de los residuos es muy cercana a 0 ($1.934921*10^{-17}$), ademas el test de Shapiro-Wilk da un resultado de $p-value=0.2599  >  0.05$, por lo tanto no se tiene evidencia suficiente para rechazar la condicion de normalidad de los residuos.

#### 6) La variabilidad de los residuos debe ser aproximadamente constante.
La prueba de homcedasticidad da como resultado $p-value= 0.0.1222 >0.05$, por lo tanto, no se tiene evidencia suficiente para rechazar la condicion de homocedasticidad.

#### 7) Independencia de residuos.
```{r}
print(durbinWatsonTest(RLMf))
```
Tambien se obtiene un p-value mayor a 0.05 por lo tanto se puede concluir que se cumple la condicion de la independencia de los residuos.

#### 8) No debe existir multicolinealidad
```{r}
#existen 4 variables con VIF mayor a 5, por lo tanto se puede concluir que existe multicolinealidad alarmante entre las variables
cat("Factores de Inflación de la Varianza:\n")
print(vif(RLMf))
cat("\nValores de Tolerancia:\n")
print(1/vif(RLMf))
```
De los resultados anteeriores se encuentran varios predictores con un $VIF$ mayor a 5, lo que indica que existe multicolinealidad entre las variables, mas importantemente, el $VIF$ de Forearm.Girth es mayor a 10, demostrando una multicolinealidad extremadamente alta.


#### 9)Las estimaciones de los coeficientes del modelo no debe estar alterados por unos pocas observaciones influyentes.
```{r}
influencePlot(RLMf)
#Distancias de cook muy bajas
```
En todos los casos anteriores se obtiene una distancia de Cook muy baja, por lo tanto no se se tiene la evidencia suficiente para rechazar el cumplimiento de la condicion.

De los resultados anteriores, hay varios factores que ponen en duda la confiabilidad del modelo, por lo que se procedera a analizar que variables eliminar

## Predictores Problematicos:

Se procede a eliminar los 2 predictores con mayor $VIF$ (Forearm.Girth y Wrist.Minimum.Girth)
```{r}
nueva_formula <- update(formularfl, . ~ . - Forearm.Girth - Wrist.Minimum.Girth)
print(nueva_formula)
RLMf2 <- lm(nueva_formula, data = datos)
summary(RLMf2)

```
Se continua con el grafico de residuos
```{r, message=FALSE, warning=FALSE}

residualPlots(RLMf2)
cat("\n")
marginalModelPlots(RLMf2)
ncvTest(RLMf2)
```
####  Distribucion normal de residuos
```{r}
set.seed(20994)
residuos<-resid(RLMf2)
#media muy cercana a 0
print(mean(residuos))

#test de normalidad
#P-value mayor a 0.05m permitiendo concluir que no existe evidencia suficiente para rechazar que lo residuos no tengan una disribucion normal
print(shapiro.test(residuos))
```
####  Independencia de residuos.
```{r}
print(durbinWatsonTest(RLMf2))
```

Hasta este paso las condiciones se siguen cumpliendo

####  No debe existir multicolinealidad
```{r}
#existen 4 variables con VIF mayor a 5, por lo tanto se puede concluir que existe multicolinealidad alarmante entre las variables
cat("Factores de Inflación de la Varianza:\n")
print(vif(RLMf2))
cat("\nValores de Tolerancia:\n")
print(1/vif(RLMf2))
```

Se obtienen mejores resultados en la inflacion de la varianza, solo una superando el umbral de 5, por lo que se puede concluir que la multicolinealidad ha disminuido, pero no se ha eliminado del todo, de todas maneras se continuara.


#### Las estimaciones de los coeficientes del modelo no debe estar alterados por unos pocas observaciones influyentes.
```{r}
influencePlot(RLMf)

```





Continuando con el ajuste

```{r}
modelo_nulo <- lm(EN ~ 1, data = datos)
anova_rlm <- anova(modelo_nulo, RLMf2, test = "LRT")

cat("Bondad de ajuste del nuevo RLM:\n")
print(anova_rlm)
```

---

## Regresión Lineal Logística con `caret`
> Usando RFE, construir un modelo de regresión logística múltiple para la variable EN que incluya el conjunto de predictores, entre dos y seis, que entregue la mejor curva ROC y que utilice validación cruzada dejando uno fuera para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura –Weight y Height respectivamente– ni IMC).

```{r, warning=FALSE}
set.seed(20994)
datos <- rbind(sobrepeso, no_sobrepeso)
datos <- datos[sample(nrow(datos)), ]  # Reordena aleatoriamente las filas


# Asegurarse de que la variable de respuesta EN sea un factor para la clasificación
datos$EN <- factor(datos$EN, levels = c(0, 1), labels = c("Sobrepeso", "NoSobrepeso"))

# Configurar el control de RFE para regresión logística (lrFuncs)
# con validación cruzada "dejando uno fuera" (LOOCV).
rfe_control_logit <- rfeControl(functions = lrFuncs, 
                                method = "LOOCV",
                                verbose = FALSE)

# Ejecutar RFE para encontrar el mejor conjunto de predictores
modelo_rfe_logit <- rfe(x = datos[, !names(datos) %in% c("Weight", "Height", "IMC", "EN")],
                        y = datos$EN,
                        # Probar subconjuntos de 2 a 6 predictores
                        sizes = 2:6, 
                        rfeControl = rfe_control_logit,
                        metric = "ROC")

# Imprimir los resultados de RFE
modelo_logit <- modelo_rfe_logit[["fit"]]
print(summary(modelo_logit))

# Imprimir los mejores predictores encontrados
mejores_predictores_logit <- predictors(modelo_rfe_logit)
print(mejores_predictores_logit)
```

#### 1. Debe existir una relación lineal entre los predictores y la respuesta transformada.

```{r}
formula_texto <- paste("EN", paste(mejores_predictores_logit, collapse = " + "), sep = " ~ ")
formula_logit <- as.formula(formula_texto)
modelo_final_logit <- glm(formula_logit, data = datos, family = binomial(link = "logit"))

summary(modelo_final_logit)


residualPlots(modelo_final_logit, fitted = FALSE)
crPlots(modelo_final_logit)

```

Dado los resultados de la prueba de curvatura, reportados por `residualPlots()`, confirman que se cumple el supuesto de linealidad entre los predictores y la respuesta transformada. Es importante decir que "Gender" genera un p de 1, además de que produce warnings de convergencia, por ahora continuaremos para analizar otros parámetros.

#### 2. Los residuos deben ser independientes entre sí.

```{r}
set.seed(20994)
durbinWatsonTest(modelo_final_logit)
```

La prueba de Durbin-Watson resultó no significativa, con un $p$ de $0.848$, por lo que se descarta que no se cumpla la condición de independencia de los residuos.

#### 3. Multicolinealidad entre los predictores.

```{r}
cat("Inflación de la varianza:\n")
print(vif(modelo_final_logit))
cat("\n")
cat("Valores de tolerancia:\n")
print(1 / vif(modelo_final_logit))
```
Los factores de inflación de varianza son relativamente bajos, entre 1 y 5, lo que indica una multicolinealidad moderada, excepto para "Gender" que da una inflación de la varianza mayor a 5 y una tolerancia menor a 0.2, por ello eliminaremos este predictor del modelo.


```{r, warning=FALSE}
# Ejecutar RFE para encontrar el mejor conjunto de predictores sin contar "Gender"
modelo_rfe_logit_v2 <- rfe(x = datos[, !names(datos) %in% c("Gender","Weight", "Height", "IMC", "EN")],
                        y = datos$EN,
                        # Probar subconjuntos de 2 a 6 predictores
                        sizes = 2:6, 
                        rfeControl = rfe_control_logit,
                        metric = "ROC")

# Imprimir los resultados de RFE
modelo_logit_v2 <- modelo_rfe_logit_v2[["fit"]]
print(summary(modelo_logit_v2))

# Imprimir los mejores predictores encontrados
mejores_predictores_logit_v2 <- predictors(modelo_rfe_logit_v2)
print(mejores_predictores_logit_v2)
```

Habiendo eliminado "Gender" del modelo, proseguiremos a revisar nuevamente las condiciones.

```{r}
formula_texto_v2 <- paste("EN", paste(mejores_predictores_logit_v2, collapse = " + "), sep = " ~ ")
formula_logit_v2 <- as.formula(formula_texto_v2)

modelo_final_logit_v2 <- glm(formula_logit_v2, data = datos, family = binomial(link = "logit"))
summary(modelo_final_logit_v2)

residualPlots(modelo_final_logit_v2, fitted = FALSE)
crPlots(modelo_final_logit_v2)
```
Ahora se obtienen valores p no significativos para todos los predictores, por lo que se concluye que se cumple el supuesto de linealidad entre los predictores y la respuesta transformada. Igualmente, hay warnings de convergencia, por lo que seguiremos revisando las métricas a detalle para evaluar la posible eliminación de otro predictor.


#### 2. Los residuos deben ser independientes entre sí.

```{r}
set.seed(20994)
durbinWatsonTest(modelo_final_logit_v2)
```

La prueba de Durbin-Watson resultó no significativa, con un $p$ de $0.854$, por lo que se descarta que no se cumpla la condición de independencia de los residuos.

#### 3. Multicolinealidad entre los predictores.

```{r}
cat("Inflación de la varianza:\n")
print(vif(modelo_final_logit_v2))
cat("\n")
cat("Valores de tolerancia:\n")
print(1 / vif(modelo_final_logit_v2))
```

Con respecto a la multicolinealidad, se obtienen factores de inflación de varianza bajos, entre 1 y 5 (de hecho, menores a 3), de esto se puede concluir que existe una multicolinealidad moderada, pero ya que estos valores son relativamente bajos, no se concluye que sean suficientemente relevantes para causar preocupación, con respecto a la tolerancia, se encuentran valores mayores a 0.3, permitiendo concluir lo mismo que con los factores de inflación.


#### 4. Tamaño de muestra (observaciones suficientes para todas las posibles combinaciones de predictores, en especial para algún nivel de una variable categórica).

Ya que los predictores son numéricos, se requiere un mínimo de 90 observaciones, considerando 15 por cada uno, por lo tanto, se cumple, ya que hay 100 observaciones.

#### 5. Las estimaciones de los coeficientes del modelo no están dominadas por casos influyentes.

```{r}
influencePlot(modelo_final_logit_v2, id = list(cex = 0.7))
```

El doble del apalancamiento promedio vendría a ser aproximadamente $2\cdot\frac{6+1}{100}=\frac{7}{50} = 0.14$. Con este valor se puede identificar que los 3 puntos, 64, 23 y 65, no cumplen con la condición de ser menores que el doble del apalancamiento promedio, lo que indica que son puntos influyentes. Sin embargo, al observar los valores correspondientes a la distancia de Cook, estos son sumamente bajos y menores que 1, por lo que no deberían influir en la línea de regresión asociada al RLog múltiple.


#### Ajuste

```{r}
modelo_nulo_logit <- glm(EN ~ 1, data = datos, family = binomial(link = "logit"))
anova_rlm <- anova(modelo_nulo_logit, modelo_final_logit_v2, test = "LRT")

cat("Bondad de ajuste del modelo RLogM:\n")
print(anova_rlm)
```

En el RLogM se puede observar una reducción de la devianza de $95.79$, con respecto al modelo nulo, y un p-value significativo de $2.2*10 ^ {-16}$ indicando que el modelo posee una buena bondad de ajuste.


#### Poder predictivo

```{r, warning=FALSE}
set.seed(20994)
modelo_ent_logit <- train(EN ~ ., data = datos[, c(mejores_predictores_logit_v2, "EN")], 
                    method = "glm",family = binomial(link = "logit"),
                    trControl = trainControl(method = "LOOCV",
                                            savePredictions = TRUE,
                                            classProbs = TRUE, summaryFunction = twoClassSummary),
                    metric = "ROC")


# Matriz de confusión general (LOOCV)
confusionMatrix(modelo_ent_logit$pred$pred, modelo_ent_logit$pred$obs)

# Probabilidades de la clase positiva
probs <- modelo_ent_logit$pred$Sobrepeso

# Clases observadas
obs <- modelo_ent_logit$pred$obs             

# Calcular curva ROC
roc_obj <- roc(obs, probs, direction = "<", levels = c("NoSobrepeso", "Sobrepeso"))

# Graficar curva ROC
plot(roc_obj, 
     main = "Curva ROC - Modelo Múltiple (LOOCV)", 
     col = "red", 
     print.auc = TRUE, 
     auc.polygon = TRUE, 
     grid = TRUE,
     auc.polygon.col = "lightpink", 
     max.auc.polygon = TRUE,
     xlab = "1 - Especificidad", 
     ylab = "Sensibilidad")

```

El modelo obtuvo una exactitud del 86%, lo que indica que clasifica correctamente la mayoría de los casos. La sensibilidad fue de 82% y la especificidad de 90%, lo que significa que identifica bien tanto a personas con sobrepeso como sin él. Además, el área bajo la curva ROC (AUC) fue de 0.939, lo que muestra un excelente rendimiento general del modelo para distinguir entre ambas clases.
