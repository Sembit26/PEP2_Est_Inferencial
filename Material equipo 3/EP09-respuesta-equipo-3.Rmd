---
title: "EP09: Regresión Lineal Múltiple"
date: "2025-06-02"
author: "Equipo 3"
output: html_document
---
## Contexto de la actividad
> Un estudio recolectó medidas anatómicas de 247 hombres y 260 mujeres (Heinz et al., 2003). El estudio incluyó nueve mediciones del esqueleto (ocho diámetros y una profundidad de hueso a hueso) y doce mediciones de grosor (circunferencias) que incluyen el tejido. 

```{r, message=FALSE, echo=FALSE, warning=FALSE}
library(car)
library(dplyr)
```

### Lectura de los datos

Se extraen los datos y se separan en conjuntos de entrenamiento y de prueba para la realización y posterior control de calidad de los modelos a confeccionar, donde se debe de excluir las variables de `Weight` y `Gender`. 
```{r, message=FALSE, warning=FALSE}
datos <- read.csv2("EP09 Datos.csv")

set.seed(1391)

# Sacar muestra aleatoria de tamaño 100 con Gender igual a 1 (hombres)
muestra <- datos[datos$Gender == 1, ] %>%
  sample_n(100)

# Separar la muestra en 70 y 30 datos
entrenamiento <- muestra[1:70, ]
prueba <- muestra[71:100, ]

# Obtener nombres de columnas excepto Weight y Gender
predictores_posibles <- setdiff(names(entrenamiento), c("Weight", "Gender"))
```

Luego, se eligen 8 predictores aletoriamente para armar el modelo RLM.

```{r, warning = FALSE, message=FALSE}
# Seleccionar 8 predictores al azar
predictores_RLM <- sample(predictores_posibles, 8)
predictores_sobra <- setdiff(predictores_posibles, predictores_RLM)

entrenamiento_filtrado<- entrenamiento %>% select(all_of(predictores_sobra))
data_RLM<- entrenamiento %>% select(c(predictores_RLM,"Weight", "Shoulder.Girth"))

cat("Posibles predictores seleccionados para RLM:\n")
predictores_RLM
```

Con los 8 predictores aleatorios ya determinados, se toman los 13 restantes y de estos debemos elegir el más apto para construir el modelo RLS, por tanto vemos los valores de correlación de estas 13 variable respecto de la variable de salida.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
cat("Posibles predictores para RLS:\n")
predictores_sobra

# Eleccion de variable para RLS
cat("Correlación para cada variable respecto de Weight:\n")
cor(entrenamiento_filtrado, y = entrenamiento[["Weight"]])
```

Dada la correlación medida, se selecciona como predictor para el RLS la variable "Shoulder.Girth".

```{r, Message=FALSE, Warning=FALSE}
RLS <- lm(Weight ~ Shoulder.Girth, data = entrenamiento)
summary(RLS)
```

Se prepara un modelo máximo con todas las variables del dataset, y el modelo incial, que en este caso corresponde al RLS ya construido.

```{r, Message=FALSE, Warning=FALSE}
RLM_max<- lm(Weight ~ ., data = data_RLM)

RLM <- step(RLS,scope=list(lower = RLS, upper = RLM_max), direction = "both", trace = "TRUE")
```

El modelo obtenido, visible en el último paso de la traza de `step()`, contiene 7 predictores, así que se debe eliminar uno de ellos para cumplir con el uso de entre 3 y 5 predictores de los obtenidos al inicio incluyendo el predictor inicial contenido en el RLS.

```{r, Message=FALSE, Warning=FALSE}
drop <- drop1(RLM, test = "F")
drop
```

Habiendo seleccionado el predictor a eliminar, se procede a actualizar el RLM quitando la variable de menor significancia y así quedamos con el RLM a utilizar de 6 predictores.

```{r, Message=FALSE, Warning=FALSE}
# Eliminar el predictor con mayor p-valor
RLM <- update(RLM, . ~ . - Chest.Girth)
summary(RLM)
```


## Generalidad / Confiabilidad 
> Tanto para el RLS cómo el RLM es importante revisar las condiciones para asegurar que el modelo generado sea generalizable.
 
### Generalidad para el RLS

#### 1. Bondad de Ajuste: 

```{r}
summary(RLS)
```

El predictor "Shoulder.Girth", en el modelo RLS, logra reducir aproximadamente el 61% de la varianza aleatoria de la variable "Weight", lo que indica un buen ajuste del modelo.

#### 2. Distribucion e Independencia: 

```{r, message=FALSE, warning=FALSE}
residualPlots(RLS, type = "rstandard",
              id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
              col = "steelblue", pch = 20, col.quad = "red")
```

```{r, message=FALSE, warning=FALSE}
set.seed(1391)
durbinWatsonTest(RLS)
```

```{r, message=FALSE, warning=FALSE}
ncvTest(RLS)
```
Al observar el grafico de residuos, se puede notar que no siguen un patrón determinado, lo que sugiere que la distribución de los residuos es aleatoria. La curva roja indica una leve curvatura, pero no es suficiente para rechazar la normalidad de los residuos, además de que la prueba de aditividad de Tukey resulto no significativa con un $p$ de $0.2030$, lo que indica que no hay evidencia suficiente para rechazar la independencia de los datos.
Adicionalmente, la prueba de Durbin-Watson da un valor $p$ de $0.736$, lo que indica que no hay evidencia de autocorrelación en los residuos del modelo. Por último, la prueba de homocedasticidad muestra un $p$ de $0.82395$, lo que sugiere que no hay evidencia suficiente para rechazar la hipótesis nula de homocedasticidad.


#### 3. Influencia de Valores Atípicos:

```{r, message=FALSE, warning=FALSE}
influencePlot(RLM, id = list(cex = 0.7))
```

El doble del apalancamiento promedio vendría a ser aproximadamente $2\cdot\frac{1+1}{70}=\frac{1}{35} = 0.029$. Con este valor se puede identificar que los 4 puntos, 2, 11, 64 y 68, no cumplen con la condición de ser menores que el doble del apalancamiento promedio, lo que indica que son puntos influyentes. Sin embargo, al observar los valores correspondientes a la distancia de Cook, estos son sumamente bajos y menores que 1, por lo que no deberían influir en la línea de regresión asociada al RLS.

#### Conclusión de condiciones
Con las pruebas anteriormente aplicadas, observamos que en su mayoría el modelo de regresión lineal simple no presenta problemas de generalización. Si bien en la prueba para valores atípicos ocurrió que varios puntos se alejaron del doble del apalancamiento promedio, no debería ser influyente en la línea de regresión.

### Generalidad para el RLM

#### 1. La variable de respuesta debe ser cuantitativa y continua, sin restricciones para su variabilidad: 
La variable "Weight" cumple con esta condición, ya que es cuantitativa y continua, representando el peso de los hombres en la muestra.

#### 2. Los predictores deben ser cuantitativos o dicotómicos: 
Los predictores seleccionados son todos cuantitativos, ya que representan medidas en centímetros.

#### 3. Los predictores deben tener algún grado de variabilidad: 

```{r}
cat("\nVarianza de 'Shoulder.Girth': ", var(data_RLM$Shoulder.Girth))
cat("\nVarianza de 'Chest.depth': ", var(data_RLM$Chest.depth))
cat("\nVarianza de 'Thigh.Girth': ", var(data_RLM$Thigh.Girth))
cat("\nVarianza de 'Bitrochanteric.diameter': ", var(data_RLM$Bitrochanteric.diameter))
cat("\nVarianza de 'Waist.Girth': ", var(data_RLM$Waist.Girth))
cat("\nVarianza de 'Age': ", var(data_RLM$Age))
```

Con este resultado se concluye que los predictores cumplen con la condición de variabilidad, ya que las variables predictoras del modelo RLM planteado tienen varianzas distintas de cero.

A continuación, se realizan gráfico de residuos, gráficos marginales y pruebas de homocedasticidad para verificar las condiciones 4, 5 y 6 de confiabilidad del modelo:

```{r, message=FALSE, warning=FALSE}

residualPlots(RLM, type = "rstandard",
              id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
              col = "steelblue", pch = 20, col.quad = "red")

cat("\n")
ncvTest(RLM)
```

#### 4. Cada predictor debe estar relacionado linealmente con la respuesta: 
En términos de los gráficos por variable del RLM, observamos que algunos tienen una tendencia lineal sumamente evidente, cómo lo son las variables `Chest.Depth`, `Waist.Girth` y `Age`. En cambio, no es tan sencillo determinar linealidad respecto de la variable de salida para las variables `Bitrochanteric.diameter`, `Shoulder.Girth` y `Thigh.Girth`. Si bien la mitad de las variables están en duda, en base al resultado del test de aditividad de Tukey $Pr(>|TestStatistic) = 0.2467 \geq 0.05$, los datos no presentan la evidencia suficiente para rechazar la condición de relación lineal.

#### 5. La distribución de los residuos debe ser cercana a la normal centrada en cero: 
Viendo el gráfico notamos que no sigue un patrón determinado, más aún la curva roja indica una curvatura leve. Observando la aleatoriedad de los puntos en el gráfico, no podemos rechazar la normalidad de los residuos.

#### 6. La variabilidad de los residuos debe ser aproximadamente constante: 
La prueba de homocedasticidad da un $p$ de $0.43221$ lo que considerando un nivel de significancia de $0.05$, se concluye que no hay evidencia suficiente para rechazar la hipótesis nula de homocedasticidad, por lo que se considera que la condición de homocedasticidad se cumple.

#### 7. Los residuos deben ser independientes entre sí:
```{r}
set.seed(1391)
db_test <- durbinWatsonTest(RLM)
print(db_test)
```
Ya que el valor $p$ es de $0.854$, se descarta la presencia de autocorrelación en los residuos del modelo, por lo que no hay evidencia de que no se cumpla la condición de independencia.

#### 8. No debe existir multicolinealidad entre los predictores:
```{r}
vif_rlm <- vif(RLM)
print(vif_rlm)
```

Para cada predictor se obtiene un factor de inflación de varianza menor a 5, entonces se concluye que hay multicolinealidad moderada entre los predictores obtenidos, no obstante, la única variable potencialmente problemática sería `Waist.Girth` pero no es suficientemente alto cómo para llegar a ser preocupante.

#### 9. Las estimaciones de los coeficientes del modelo no deben estar alterados por unas pocas observaciones influyentes:
```{r}  
influencePlot(RLM, id = list(cex = 0.7))
```

El doble del apalancamiento promedio vendría a ser $2\cdot\frac{6+1}{70}=\frac{1}{5} = 0.2$. Notemos que, para los puntos obtenidos, solamente 2 puntos, 2 y 64, no cumplen con la condición de ser menores que el doble del apalancamiento promedio, aun así en vista de los valores correspondientes a la distancia de Cook, siendo estos sumamente bajos y menores que 1, por lo que no deberían influir en la línea de regresión asociada al RLM.

#### Conclusión de condiciones
En retrospectiva el modelo RLM parece ser confiable puesto que se observaron detenidamente las 9 condiciones, y si bien algunas presentan sospechas, no es lo suficientemente significativo cómo para descartar la confiabilidad del modelo.


## Calidad Predictiva
> Una vez vistas las condiciones de cada uno de los modelos confeccionados, se proceden a comparar uno con el otro.

#### Comparación de ANOVA entre RLS y RLM
```{r, warning=FALSE}
comparacion_anova <- anova(RLS, RLM)
print(comparacion_anova)
```

Dado que el test de ANOVA entregó un p-value de $2.2 \cdot 10^{-16}$, que implica un cambio sumamente significativo entre el RLS y el RLM, más aún evidenciado por los valores de RSS entregados por el ANOVA.

#### Calidad predictiva para RLS
```{r, warning=FALSE}

# conjunto entrenamiento
rls_rmse_entrenamiento <- sqrt(mean(resid(RLS) ** 2))

# Conjunto de prueba
predicciones <- predict(RLS, prueba)
error <- prueba$Weight - predicciones
rls_rmse_prueba <- sqrt(mean(error**2))

# Porcentaje cambio
rls_porcentaje_cambio <- 100*((rls_rmse_prueba - rls_rmse_entrenamiento) / rls_rmse_entrenamiento)
```

#### Calidad predictiva para RLM
```{r, warning=FALSE}

# conjunto entrenamiento
rlm_rmse_entrenamiento <- sqrt(mean(resid(RLM) ** 2))

# Conjunto de prueba
predicciones <- predict(RLM, prueba)
error <- prueba$Weight - predicciones
rlm_rmse_prueba <- sqrt(mean(error**2))
# Porcentaje cambio
rlm_porcentaje_cambio <- 100*((rlm_rmse_prueba - rlm_rmse_entrenamiento) / rlm_rmse_entrenamiento)
```

#### Resultados de calidad predictiva de RLS y RLM

```{r, warning=FALSE, echo=FALSE}
cat("Error asociado al conjunto de entrenamiento modelo lineal simple: ", rls_rmse_entrenamiento)
cat("Error asociado al conjunto de entrenamiento modelo lineal múltiple: ", rlm_rmse_entrenamiento)
cat("Error asociado al conjunto de prueba modelo lineal simple: ", rls_rmse_prueba)
cat("Error asociado al conjunto de prueba modelo lineal múltiple: ", rlm_rmse_prueba)
```

## Conclusiones
```{r, warning=FALSE, echo=FALSE}
cat("Porcentaje de error para RLS: ", rls_porcentaje_cambio)
cat("Porcentaje de error para RLM: ", rlm_porcentaje_cambio)
```

Viendo la diferencia por conjunto, haciendo un antes y un después entre la inserción de las variables predictoras aleatorias, se ve una mejoría en ambos conjuntos evidenciada por la disminución significativa del error. Por lo tanto, el RLM tiene una mejor capacidad predictiva que el RLS. 
Notar que el modelo RLM no es una mejora directa por sobre el RLS, es importante mencionar el porcentaje de error asociado al RLM, siendo este cercano a $20\%$, mientras que el RLS tiene un porcentaje de error cercano a $3.5\%$, este porcentaje nos indica la fidelidad dentro del dataset del modelo, esto implica que la diferencia entre los valores que ya existen y los generados por el modelo, por tanto el incremento nos indica una desconexión entre la predicción y valores reales, esto indica la presencia de sobreajuste en el RLM que compromete la generalidad frente a nuevos datos. Entonces se debe de continuar con el análisis eliminando posibles predictores que afecten al modelo.